---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<div style="text-align: center; margin-bottom: 2em;">
  <h1 style="font-size: 2.5em; color: #494e52;">About</h1>
</div>

## About Me

I am a postgraduate student with background experience in medical image analysis and object detection. That was my starting point, but I am now transitioning and self-learning in the field of embodied intelligence. I am interested in how AI can be integrated with physical systems to interact with the real world. As a student, I hope to bridge my past experience in computer vision with new knowledge in robotics and embodied AI systems.

---

## Learning Journey

<div class="learning-journey">
  <p>As someone new to the field of embodied AI, I believe in the power of continuous learning and exploration. My approach to this exciting field includes:</p>
  
  <div class="journey-point">
    <i class="fas fa-book-open" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span><strong>Learning from fundamentals</strong>: Building a solid theoretical foundation before diving into advanced concepts</span>
  </div>
  
  <div class="journey-point">
    <i class="fas fa-laptop-code" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span><strong>Hands-on practice</strong>: Implementing basic concepts in small projects to reinforce understanding</span>
  </div>
  
  <div class="journey-point">
    <i class="fas fa-users" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span><strong>Learning from the community</strong>: Following research papers, tutorials, and discussions from experts in the field</span>
  </div>
  
  <div class="journey-point">
    <i class="fas fa-sync-alt" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span><strong>Iterative improvement</strong>: Embracing the learning curve and using each challenge as an opportunity to grow</span>
  </div>
  
  <div class="journey-point">
    <i class="fas fa-puzzle-piece" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span><strong>Connecting knowledge domains</strong>: Finding ways to apply my background in computer vision to new concepts in robotics</span>
  </div>
</div>

---

## Research Interests

<div class="research-interests">
  <div>
    <i class="fas fa-brain" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <strong>Medical AI</strong>: Previous experience with deep learning for medical image analysis, disease prediction and diagnosis, multi-modal clinical data integration
  </div>
  <div>
    <i class="fas fa-robot" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <strong>Embodied Intelligence</strong>: Self-learning about physical AI systems, robot learning, sensorimotor control, and human-robot interaction
  </div>
  <div>
    <i class="fas fa-eye" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <strong>Computer Vision</strong>: Experience with attention-based object detection and image segmentation
  </div>
  <div>
    <i class="fas fa-project-diagram" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <strong>Multi-modal Learning</strong>: Exploring Vision-Language-Action(VLA) model for embodied AI systems
  </div>
</div>

---

## Education

<div class="education">
  <div class="education-entry">
    <h3><i class="fas fa-graduation-cap" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>Master in Artificial Intelligence and Adaptive System</h3>
    <p><em>Sussex Artificial Intelligence Institute, Zhejiang Gongshang University</em><br>
    Hangzhou, China<br>
    Sept 2024 -- Present</p>
    <ul>
      <li>Current Study: Algorithms with applications in embodied intelligence</li>
      <li>Key Courses: Intelligence in Animals and Machines, Intelligent Systems Techniques, Image Processing, Machine Learning</li>
    </ul>
  </div>

  <div class="education-entry">
    <h3><i class="fas fa-graduation-cap" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>Bachelor in Computer Science and Technology</h3>
    <p><em>Wenzhou Business College</em><br>
    Wenzhou, China<br>
    Sept 2019 -- June 2023</p>
    <ul>
      <li>GPA: 3.41/5.0 (84.7/100)</li>
      <li>Undergraduate Thesis: "Smoking behavior detection based on deep learning and skeletal framework"</li>
    </ul>
  </div>
</div>

---

## Research Experience

<div class="experience">
  <div class="experience-entry">
    <h3><i class="fas fa-flask" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>Research Intern</h3>
    <p><em>Wenzhou Medical University First Affiliated Hospital - Hepato-Pancreato-biliary surgery Laboratory</em><br>
    Wenzhou, China<br>
    Sept 2022 -- Jan 2023</p>
    <ul>
      <li>Participated in the development of medical image preprocessing software for clinical applications, contributing to software copyright registration</li>
      <li>Assisted in designing and implementing deep learning models for leukemia diagnosis based on tongue image analysis</li>
      <li>Helped create machine learning algorithms for exosome feature analysis in hepatocellular carcinoma research</li>
      <li>Collaborated with medical professionals to validate the effectiveness of developed algorithms and systems</li>
    </ul>
  </div>

  <div class="experience-entry">
    <h3><i class="fas fa-users" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>Student Team Leader</h3>
    <p><em>National Innovation Training Project, Wenzhou Business College</em><br>
    June 2022 -- June 2023</p>
    <ul>
      <li>Participated in research on enhancing YOLO architecture with attention mechanisms for real-time object detection</li>
      <li>Studied the application of self-attention module and its impact on detection accuracy</li>
      <li>Worked with a team of 4 students, learning about technical development and experimental validation</li>
      <li>Contributed to the project's intellectual property outcomes, including patent applications and software copyrights</li>
    </ul>
  </div>
</div>

---

## Current Learning Focus

<div class="learning-focus">
  <ul>
    <li><i class="fas fa-graduation-cap" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> <strong>Foundations of Robotics</strong>: Studying core robotics concepts including kinematics, dynamics, and control systems</li>
    <li><i class="fas fa-code-branch" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> <strong>Reinforcement Learning</strong>: Learning policies for robotic control and decision-making in physical environments</li>
    <li><i class="fas fa-microchip" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> <strong>Vision-Language-Action Models</strong>: Exploring how multimodal inputs can guide embodied agents to perform real-world tasks</li>
    <li><i class="fas fa-sitemap" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> <strong>Sensorimotor Learning</strong>: Understanding how perception and action can be effectively integrated in AI systems</li>
    <li><i class="fas fa-flask" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> <strong>Simulation Environments</strong>: Working with platforms like MuJoCo, Isaac Gym, and Habitat for embodied AI research</li>
  </ul>
</div>

---

## Learning Resources

<div class="learning-resources">
  <p>As a self-directed learner in embodied AI, I'm currently studying from these resources:</p>
  
  <div class="resource-category">
    <h3><i class="fas fa-book" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> Books & Textbooks</h3>
    <ul>
      <li>"Modern Robotics: Mechanics, Planning, and Control" by Kevin Lynch and Frank Park</li>
      <li>"Reinforcement Learning: An Introduction" by Richard S. Sutton and Andrew G. Barto</li>
      <li>"Probabilistic Robotics" by Sebastian Thrun, Wolfram Burgard, and Dieter Fox</li>
    </ul>
  </div>
  
  <div class="resource-category">
    <h3><i class="fas fa-laptop" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> Online Courses</h3>
    <ul>
      <li>Stanford CS231n: Convolutional Neural Networks for Visual Recognition</li>
      <li>UC Berkeley CS285: Deep Reinforcement Learning</li>
      <li>MIT 6.S094: Deep Learning for Self-Driving Cars</li>
    </ul>
  </div>
  
  <div class="resource-category">
    <h3><i class="fas fa-code-branch" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> Code Repositories & Projects</h3>
    <ul>
      <li>OpenAI Gym and MuJoCo environments for reinforcement learning practice</li>
      <li>PyBullet physics simulator for robotics</li>
      <li>Open-source computer vision libraries and tutorials</li>
    </ul>
  </div>
  
  <div class="resource-category">
    <h3><i class="fas fa-user-graduate" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> Research Papers</h3>
    <ul>
      <li>Survey papers on robot learning and embodied AI</li>
      <li>Case studies on successful applications of computer vision in robotics</li>
      <li>State-of-the-art papers in multimodal learning for embodied agents</li>
    </ul>
  </div>
</div>

---

## Projects

<div class="projects">
  <div class="project-entry">
    <h3><i class="fas fa-project-diagram" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>Enhanced YOLO with Attention Mechanism</h3>
    <p><em>Object Detection Research Project</em></p>
    <p>Implemented an improved YOLO architecture incorporating self-attention modules to enhance detection accuracy while maintaining real-time performance. The project specifically focused on:</p>
    <ul>
      <li>Designing a lightweight attention mechanism compatible with YOLO's architecture</li>
      <li>Benchmarking performance improvements on standard datasets</li>
      <li>Optimizing for real-time inference on resource-constrained devices</li>
    </ul>
    <p><strong>Technologies</strong>: PyTorch, YOLO, Computer Vision</p>
  </div>
  
  <div class="project-entry">
    <h3><i class="fas fa-microscope" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>Medical Image Preprocessing Pipeline</h3>
    <p><em>Clinical Software Development</em></p>
    <p>Developed a comprehensive preprocessing pipeline for medical images to support clinical diagnostic applications. This software:</p>
    <ul>
      <li>Standardized image formats from multiple medical imaging devices</li>
      <li>Implemented noise reduction and artifact removal algorithms</li>
      <li>Created an intuitive interface for medical professionals</li>
      <li>Resulted in registered software copyright</li>
    </ul>
    <p><strong>Technologies</strong>: Python, OpenCV, Medical Imaging Libraries</p>
  </div>
  
  <div class="project-entry">
    <h3><i class="fas fa-smoking" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>Smoking Behavior Detection System</h3>
    <p><em>Undergraduate Thesis Project</em></p>
    <p>Designed and implemented a system to automatically detect smoking behavior using pose estimation and deep learning. The system:</p>
    <ul>
      <li>Utilized skeletal framework analysis to identify characteristic smoking gestures</li>
      <li>Employed temporal sequence modeling to differentiate smoking from similar actions</li>
      <li>Achieved high accuracy in both controlled and real-world environments</li>
    </ul>
    <p><strong>Technologies</strong>: Deep Learning, Human Pose Estimation, Action Recognition</p>
  </div>
</div>

---

## Skills

<div class="skills">
  <div class="skill-category">
    <h3><i class="fas fa-code" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> Programming</h3>
    <p>Python, C, Java, C#, SQL, JavaScript, Vue</p>
  </div>
  
  <div class="skill-category">
    <h3><i class="fas fa-brain" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> Deep Learning</h3>
    <p>PyTorch, TensorFlow, Computer Vision, NLP</p>
  </div>
  
  <div class="skill-category">
    <h3><i class="fas fa-tools" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> Research Tools</h3>
    <p>LaTeX, Git, Linux</p>
  </div>
  
  <div class="skill-category">
    <h3><i class="fas fa-chart-bar" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> Data Analysis</h3>
    <p>Statistical Analysis, Data Visualization</p>
  </div>
  
  <div class="skill-category">
    <h3><i class="fas fa-globe" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> Languages</h3>
    <p>English (IELTS 6.0: L:6.5, R:6.5, W:5.5, S:6.0)</p>
    <p>CET-6 467</p>
  </div>
  
  <div class="skill-category">
    <h3><i class="fas fa-certificate" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i> Certifications</h3>
    <p>DevCloud Summer Training Camp (Huawei), Python, AI, Deep Learning Basics (Shandong University)</p>
  </div>
</div>

---

## Questions I'm Exploring

<div class="questions-exploring">
  <p>As a newcomer to embodied AI, I'm particularly curious about these questions:</p>
  
  <div class="question-entry">
    <i class="fas fa-question-circle" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span>How can we bridge the gap between computer vision systems and physical robot actions?</span>
  </div>
  
  <div class="question-entry">
    <i class="fas fa-question-circle" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span>What are the most effective approaches for robots to learn from limited demonstrations?</span>
  </div>
  
  <div class="question-entry">
    <i class="fas fa-question-circle" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span>How can medical imaging expertise contribute to better perceptual systems for robots?</span>
  </div>
  
  <div class="question-entry">
    <i class="fas fa-question-circle" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span>What are the challenges in transferring learning from simulated to real-world environments?</span>
  </div>
  
  <div class="question-entry">
    <i class="fas fa-question-circle" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span>How can multi-modal learning help robots better understand and interact with their surroundings?</span>
  </div>
</div>

---

## Future Goals

<div class="future-goals">
  <p>As I continue my academic and research journey in embodied AI, I aim to:</p>
  
  <div class="goal-entry">
    <i class="fas fa-lightbulb" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span><strong>Contribute to research</strong> at the intersection of computer vision, robotics, and reinforcement learning</span>
  </div>
  
  <div class="goal-entry">
    <i class="fas fa-users" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span><strong>Collaborate with interdisciplinary teams</strong> to develop AI systems that can safely and effectively interact with humans and their environments</span>
  </div>
  
  <div class="goal-entry">
    <i class="fas fa-university" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span><strong>Pursue doctoral studies</strong> focused on innovative applications of embodied intelligence in healthcare or assistive technologies</span>
  </div>
  
  <div class="goal-entry">
    <i class="fas fa-hands-helping" style="font-size: 1.2em; color: #494e52; margin-right: 0.5em;"></i>
    <span><strong>Develop AI solutions</strong> that address real-world challenges and improve quality of life</span>
  </div>
</div>

<style>
  .research-interests div, 
  .education-entry, 
  .experience-entry,
  .skill-category,
  .project-entry,
  .goal-entry,
  .journey-point,
  .resource-category,
  .question-entry {
    margin-bottom: 1.5em;
  }
  
  .education-entry h3,
  .experience-entry h3,
  .skill-category h3,
  .project-entry h3,
  .resource-category h3 {
    margin-bottom: 0.5em;
    color: #494e52;
  }
  
  .learning-focus ul,
  .future-goals ul,
  .resource-category ul {
    list-style-type: none;
    padding-left: 1em;
  }
  
  /* 统一图标样式 */
  .fa, .fas, .far, .fab {
    color: #494e52;
  }
  
  .section-icon {
    font-size: 1.2em;
    margin-right: 0.5em;
    color: #494e52;
  }
  
  .learning-focus i,
  .future-goals i,
  .journey-point i,
  .question-entry i {
    margin-right: 0.5em;
    color: #494e52;
  }
  
  .goal-entry,
  .journey-point,
  .question-entry {
    display: flex;
    align-items: flex-start;
    margin-bottom: 1em;
  }
  
  .skills {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
    grid-gap: 1em;
  }
  
  .project-entry,
  .resource-category {
    padding: 1em;
    background-color: #f8f9fa;
    border-radius: 5px;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
  }
  
  .learning-journey p,
  .learning-resources p,
  .questions-exploring p {
    margin-bottom: 1.5em;
    font-style: italic;
  }
  
  @media (max-width: 768px) {
    .skills {
      grid-template-columns: 1fr;
    }
  }
</style>

{% comment %}
Template information removed. This site uses the Academic Pages template.
{% endcomment %}
