---
layout: archive-cn
title: "个人简历"
permalink: /cn/cv/
author_profile: true
redirect_from:
  - /cn/resume
---

{% include base_path %}

<div style="text-align: center; margin-bottom: 1.5em;">
  <p style="font-size: 1.1em; color: var(--global-text-color); font-style: italic; max-width: 800px; margin: 0 auto;">
    有计算机视觉与医学人工智能基础的研究生 | 学习具身智能
  </p>
  
  <div class="download-button">
    <a href="{{ base_path }}/files/CV-cn.pdf" class="btn btn-primary"><i class="fas fa-download"></i> 下载简历 (PDF)</a>
  </div>
</div>

---

## 教育背景

<div class="education">
  <div class="education-entry">
    <h3><i class="fas fa-graduation-cap" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>人工智能与自适应系统硕士</h3>
    <p><em>萨塞克斯人工智能学院，浙江工商大学</em><br>
    中国杭州 | 2024-至今</p>
    <ul>
      <li><strong>核心课程：</strong>动物与机器中的智能，智能系统技术，图像处理，自然语言处理，机器学习</li>
      <li><strong>导师：</strong>Peter Wijeratne助理教授（萨塞克斯大学）和谢满德教授（浙江工商大学）</li>
      <li><strong>研究方向：</strong>将物理模型整合到VAE框架中，提高潜在空间的可解释性。</li>
      <li><strong>预计毕业时间：</strong>2026年3月</li>
    </ul>
  </div>

  <div class="education-entry">
    <h3><i class="fas fa-graduation-cap" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>计算机科学与技术学士</h3>
    <p><em>温州商学院</em><br>
    中国温州 | 2019-2023</p>
    <ul>
      <li><strong>GPA：</strong> 3.41/5.0 (84.7/100)</li>
      <li><strong>毕业论文：</strong> "基于深度学习和骨架框架的吸烟行为检测"</li>
      <li><strong>相关课程：</strong> 数据结构与算法，Python编程，数据分析，机器学习</li>
      <li><strong>论文指导教师：</strong> 匡芳君教授</li>
    </ul>
  </div>
</div>

---

## 项目与实习经历

<div class="experience">
  <div class="experience-entry">
    <h3><i class="fas fa-flask" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>实习学生</h3>
    <p><em>温州医科大学附属第一医院 - 肝胆胰外科实验室</em><br>
    中国温州 | 2022年9月 - 2023年1月</p>
    <ul>
      <li>协助开发临床应用的医学图像预处理软件，获得软件著作权登记（2022SR0252378）</li>
      <li>参与基于舌象分析的白血病诊断深度学习模型开发</li>
      <li>协助创建肝细胞癌研究中的外泌体特征分析机器学习算法</li>
      <li><strong>技术：</strong> PyTorch, TensorFlow, OpenCV</li>
    </ul>
  </div>

  <div class="experience-entry">
    <h3><i class="fas fa-users" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>学生团队负责人，国家级大学生创新训练项目</h3>
    <p><em>温州商学院</em><br>
    2022年6月 - 2023年6月</p>
    <ul>
      <li>作为团队负责人与其他4名同学合作，探索使用注意力机制增强YOLO模型</li>
      <li>尝试实现并测试自注意力模块修改方案，探索提高检测准确性的方法</li>
      <li>在团队合作下获得了3项软件著作权和递交1项发明专利申请</li>
      <li><strong>技术：</strong> PyTorch, YOLO, 计算机视觉, OpenCV</li>
      <li><strong>指导教师：</strong> 张思扬教授</li>
    </ul>
  </div>
</div>

---

## 已发表论文

<div class="publications">
  <div class="paper">
    <h3><i class="fas fa-file-alt" style="font-size: 1.2em; margin-right: 0.5em; color: var(--global-text-color);"></i>Machine Learning Identifies Exosome Features Related to Hepatocellular Carcinoma</h3>
    <p><strong>期刊：</strong> <em>Frontiers in Cell and Developmental Biology</em> (2022年9月)</p>
    <p><strong>作者：</strong>  Kai Zhu, Qiqi Tao, <strong>Jiatao Yan</strong>, Zhichao Lang, Xinmiao Li, Yifei Li, Congcong Fan, Zhengping Yu</p>
    <p><strong>DOI：</strong> <a href="https://doi.org/10.3389/fcell.2022.1020415" target="_blank">10.3389/fcell.2022.1020415</a></p>
    <p><strong>影响因子：</strong> 5.8</p>
    <p class="contribution"><strong>共同第一作者（位次第三）</strong>：负责开发机器学习算法，用于肝细胞癌研究中的外泌体特征分析和分类。参与随机森林算法的设计和实现，用于预后特征开发。</p>
  </div>
  
  <div class="paper">
    <h3><i class="fas fa-file-alt" style="font-size: 1.2em; margin-right: 0.5em; color: var(--global-text-color);"></i>Multi-omics and Machine Learning-driven CD8+ T Cell Heterogeneity Score for Prognosis</h3>
    <p><strong>期刊：</strong> <em>Molecular Therapy Nucleic Acids</em> (2024年12月)</p>
    <p><strong>作者：</strong> Di He, Zhan Yang, Tian Zhang, Yaxian Luo, Lianjie Peng, <strong>Jiatao Yan</strong>, Tao Qiu, Jingyu Zhang, Luying Qin, Zhichao Liu, Xiaoting Zhang, Lining Lin, Mouyuan Sun</p>
    <p><strong>DOI：</strong> <a href="https://doi.org/10.1016/j.omtn.2024.102413" target="_blank">10.1016/j.omtn.2024.102413</a></p>
    <p><strong>影响因子：</strong> 6.4</p>
    <p class="contribution">贡献：帮助在HNSCC研究中实施各种机器学习算法用于关键基因识别。</p>
  </div>

  <div class="paper">
    <h3><i class="fas fa-file-alt" style="font-size: 1.2em; margin-right: 0.5em; color: var(--global-text-color);"></i>Using Multiomics and Machine Learning: Insights into Improving the Outcomes of Clear Cell Renal Cell Carcinoma via the SRD5A3-AS1/hsa-let-7e-5p/RRM2 Axis</h3>
    <p><strong>期刊：</strong> <em>ACS Omega</em> (2025年6月)</p>
    <p><strong>作者：</strong> Mouyuan Sun, Zhan Yang, Yaxian Luo, Luying Qin, Lianjie Peng, Chaoran Pan, <strong>Jiatao Yan</strong>, Tao Qiu, Yan Zhang</p>
    <p><strong>DOI：</strong> <a href="https://doi.org/10.1021/acsomega.5c01337" target="_blank">10.1021/acsomega.5c01337</a></p>
    <p><strong>影响因子：</strong> 3.7</p>
    <p class="contribution">贡献：实现用于识别SRD5A3-AS1/hsa-let-7e-5p/RRM2重要特征的有关机器学习算法。</p>
  </div>
  
</div>

<!-- ---

## 审稿中的论文

<div class="manuscripts">

  <div class="paper">
    <h3><i class="fas fa-file-alt" style="font-size: 1.2em; margin-right: 0.5em; color: var(--global-text-color);"></i>Using Multiomics and Machine Learning: Insights into Improving the Outcomes of Clear Cell Renal Cell Carcinoma via SRD5A3-AS1/hsa-let-7e-5p/RRM2 Axis</h3>
    <p><strong>期刊：</strong> <em>ACS Omega</em> (提交时间: 2025年2月12日 - 审稿中)</p>
    <p><strong>作者：</strong>  Mouyuan Sun, Zhan Yang, Yaxian Luo, Luying Qin, Lianjie Peng, Chaoran Pan, <strong>Jiatao Yan</strong>, Tao Qiu, Yan Zhang</p>
    <p class="contribution">贡献：实现用于识别SRD5A3-AS1/hsa-let-7e-5p/RRM2重要特征的有关机器学习算法。</p>
  </div>
  
</div> -->

---

## 准备中的论文

<div class="manuscripts">
  <div class="paper">
    <h3><i class="fas fa-file-alt" style="font-size: 1.2em; margin-right: 0.5em; color: var(--global-text-color);"></i>Deep Learning Model for Survival Prediction of Localized Upper Tract Urothelial Carcinoma Based on Multi-Phase CT Images and Clinical Data</h3>
    <p><strong>修订中</strong></p>
    <p><strong>作者：</strong>  Kai Zhu, Binwei Lin, <strong>Jiatao Yan</strong>, Honghui Zhu, Wei Chen, Xin Yao, Fengyan You, Yue Pan, Feng Wang, Peng Xia, Yeping Li, Lianguo Chen, Zhixian Yu, Shouliang Miao, Xiaomin Gao</p>
    <p class="contribution"><strong>共同第一作者（位次第三）</strong>：设计并实现用于分析多相位CT图像的深度学习架构。开发将影像特征与临床数据整合以创建综合预测模型的方法，用于上尿路上皮癌的生存预测。参与模型验证和性能优化。</p>
  </div>

  <div class="paper">
    <h3><i class="fas fa-file-alt" style="font-size: 1.2em; margin-right: 0.5em; color: var(--global-text-color);"></i>YOLOv11-LCDFS: Enhanced Smoking Detection With Low-light Enhancement</h3>
    <p><strong>修订中</strong></p>
    <p><strong>作者：</strong> <strong>Jiatao Yan</strong>, Zhuzikai Zheng, Zhengtan Yang, Hao Jiang, Peichen Wang, Fangjun Kuang, Siyang Zhang</p>
    <p class="contribution"><strong>第一作者</strong>：开发一种基于YOLO的架构，集成低光照增强功能、损失函数、注意力机制和优化的上采样技术，来提高在不同光照条件下的检测能力。</p>
  </div>
</div>

---

## 软件著作权与发明专利

<div class="patents">
  <div class="patent-item">
    <h3><i class="fas fa-file-contract" style="font-size: 1.2em; margin-right: 0.5em; color: var(--global-text-color);"></i>专利申请</h3>
    <p><strong>名称：</strong> 吸烟行为识别摄像头及判定方法</p>
    <p><strong>申请号：</strong> 202310277784.1</p>
    <p><strong>状态：</strong> 申请流程已完成 - 因学历要求而非技术原因撤回</p>
    <p><strong>发明人：</strong> 严佳涛, 张思扬, 匡芳君, 王培臣, 郑朱子恺, 蒋昊, 杨政潭, 包瀚文, 夏春秋</p>
    <p><strong>简介：</strong> 结合姿态估计的公共场所吸烟行为实时检测方法。</p>
  </div>
  
  <div class="software-copyrights">
    <h3><i class="fas fa-file-code" style="font-size: 1.2em; margin-right: 0.5em; color: var(--global-text-color);"></i>软件著作权</h3>
    <ul>
      <li>
        <strong>医学图像计算软件</strong> (2022SR0252378)<br>
        <em>授权时间: 2022年4月</em><br>
      </li>
      <li>
        <strong>人体骨架识别软件</strong> (2022SR1258998)<br>
        <em>授权时间: 2022年10月</em><br>
      </li>
      <li>
        <strong>香烟识别软件</strong> (2022SR1277520)<br>
        <em>授权时间: 2022年10月</em><br>
      </li>
      <li>
        <strong>吸烟行为检测软件</strong> (2022SR1277521)<br>
        <em>授权时间: 2022年10月</em><br>
      </li>
    </ul>
  </div>
</div>

---

## 学术成果与奖项

<div class="achievements">

  <div class="achievement-item">
    <div class="achievement-content">
      <h4><i class="fas fa-wave-square" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>耶鲁/北卡罗来纳州大学教堂山分校 - 地球物理波形反演</h4>
      <p><strong>排名 161/890</strong> | 前19% | Kaggle全球竞赛 | 进行中（剩余1个月）</p>
    </div>
  </div>

  <div class="achievement-item">
    <div class="achievement-content">
      <h4><i class="fas fa-microscope" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>BYU - 细菌鞭毛马达定位 2025</h4>
      <p><strong>排名 335/1175</strong> | 前29% | Kaggle全球竞赛 | 2025.06.05</p>
    </div>
  </div>
  
  <div class="achievement-item">
    <div class="achievement-content">
      <h4><i class="fas fa-chart-line" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>预测卡路里消耗竞赛</h4>
      <p><strong>排名 178/4316</strong> | 前5% | Kaggle全球竞赛 | 2025.06.01</p>
    </div>
  </div>

  <div class="achievement-item">
    <div class="achievement-content">
      <h4><i class="fas fa-trophy" style="font-size: 1.2em; color:rgb(184, 115, 51); margin-right: 0.5em;"></i>斯坦福RNA 3D折叠竞赛</h4>
      <p><strong>铜牌</strong> | <strong>排名 143/1516</strong> | 前10% | Kaggle全球竞赛 | 截止时间2025.5.23</p>
    </div>
  </div>

  <div class="achievement-item">
    <div class="achievement-content">
      <h4><i class="fas fa-chart-line" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>预测播客收听时间竞赛</h4>
      <p><strong>排名 116/3310</strong> | 前4% | Kaggle全球竞赛 | 2025.05.01</p>
    </div>
  </div>
  
  <div class="achievement-item">
    <div class="achievement-content">
      <h4><i class="fas fa-chart-line" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>HuBMAP + HPA 竞赛</h4>
      <p><strong>排名 442/1174</strong> | 前38% | Kaggle全球竞赛 | 2022年9月</p>
    </div>
  </div>
  
  <div class="achievement-item">
    <div class="achievement-content">
      <h4><i class="fas fa-medal" style="font-size: 1.2em; color: #CD7F32; margin-right: 0.5em;"></i>第18届"挑战杯"大学生竞赛</h4>
      <p><strong>铜牌</strong> | 浙江省级 | 2023年5月</p>
    </div>
  </div>
  
  <div class="achievement-item">
    <div class="achievement-content">
      <h4><i class="fas fa-award" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>第4届全国"传智杯"IT技能竞赛</h4>
      <p><strong>省级优秀奖</strong> | 浙江省 | 2021年12月</p>
    </div>
  </div>
  
  <div class="achievement-item">
    <div class="achievement-content">
      <h4><i class="fas fa-award" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>2023年温州计算机学会学生会员创新创业奖</h4>
      <p><strong>三等奖</strong> | 温州 | 2024年4月</p>
    </div>
  </div>
</div>

---

## 项目经历

<div class="projects">
  <div class="project-entry">
    <h3><i class="fas fa-project-diagram" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>YOLOv11-LCDFS：结合低光照增强的吸烟检测探索</h3>
    <div class="project-details">
      <p>在本科吸烟检测研究基础上，学习如何提高在复杂光照条件下的目标检测能力。尝试探索基于YOLO架构的改进方法，学习针对低光照环境的特殊处理技术。<a href="https://github.com/M0M0KO/YOLOv11-LCDFS" target="_blank"><i class="fab fa-github"></i> GitHub</a></p>
      <ul>
        <li>探索针对低光照目标检测场景的改进损失函数</li>
        <li>学习在不同光照条件下关注关键视觉特征的注意力机制实现方法</li>
        <li>尝试优化上采样技术以在黑暗环境中保留细节信息</li>
        <li>探索将轻量级低光照增强模块集成到检测流程中的方法</li>
      </ul>
      <p><strong>使用的技术：</strong> PyTorch, YOLO, 计算机视觉, CUDA, 注意力机制</p>
      <p><strong>状态：</strong> 进行中（2025年4月）</p>
      <p><strong>相关成果：</strong> 正在准备的论文（作为参与者）</p>
    </div>
  </div>

  <div class="project-entry">
    <h3><i class="fas fa-microscope" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>多模态3D医学图像分割</h3>
    <div class="project-details">
      <p>开发多模态3D医学图像分割系统，整合T2加权成像和扩散加权成像(DWI)数据，实现多种深度学习架构对比研究。<a href="https://github.com/M0M0KO/multi-modal-medical" target="_blank"><i class="fab fa-github"></i> GitHub</a></p>
      <ul>
        <li>实现多模态医学影像数据处理，包括NIfTI格式处理、强度归一化和多掩码合并</li>
        <li>开发实现3D分割架构：3D U-Net、Swin-UNETR(基于Transformer)、TransUNet和DeepLabV3Plus</li>
        <li>建立数据匹配系统，处理T2和DWI影像的时间和空间对齐</li>
        <li>设计3D体积到2D切片的转换流程，支持不同深度学习框架的数据格式要求</li>
      </ul>
      <p><strong>使用的技术：</strong> Python, PyTorch, NiBabel, MONAI, 3D分割, Transformer架构, 多模态融合, NumPy</p>
      <p><strong>状态：</strong> 进行中（2025年4月）</p>
      <p><strong>相关成果：</strong> 参与论文准备工作</p>
    </div>
  </div>

  <div class="project-entry">
    <h3><i class="fas fa-disease" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>基于深度学习的疾病检测系统</h3>
    <div class="project-details">
      <p>开发针对医学影像的目标检测系统，关注糖尿病足溃疡检测，实现不同的YOLOv8架构变体进行系统性对比研究。<a href="https://github.com/yanjiatao/diabetic-wound-detection" target="_blank"><i class="fab fa-github"></i> GitHub</a></p>
      <ul>
        <li>实现多种注意力机制(GAM、CBAM、ECA、CoordAtt、TripletAttention)增强YOLOv8架构的特征提取能力</li>
        <li>集成上采样技术(CARAFE、DySample)和动态卷积，提高小目标检测精度和特征图分辨率</li>
        <li>设计基于三元组损失、Inner-CIoU和Focus Loss的自定义损失函数，优化医学图像中的目标检测性能</li>
        <li>建立实验框架，通过模型变体的比较，验证不同技术组合在临床场景中的有效性</li>
      </ul>
      <p><strong>使用的技术：</strong> PyTorch, YOLOv8, 注意力机制, 动态卷积, 自定义损失函数, 上采样技术, 医学图像处理</p>
      <p><strong>时间：</strong> 2024年8月</p>
    </div>
  </div>

  <div class="project-entry">
    <h3><i class="fas fa-shield-alt" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>Twitter质量与垃圾信息检测系统</h3>
    <div class="project-details">
      <p>开发机器学习系统用于Twitter内容质量评估和垃圾信息检测，实现传统机器学习和深度学习两种方法对比。<a href="https://github.com/M0M0KO/twitter-spam-detection" target="_blank"><i class="fab fa-github"></i> GitHub</a></p>
      <ul>
        <li>处理包含11,968条推文的数据集，进行文本预处理和特征工程</li>
        <li>创建复合特征：关注者关注比率、每关注者行动数等用户行为指标，结合TF-IDF文本特征</li>
        <li>实现朴素贝叶斯分类器（网格搜索优化）和双层LSTM深度学习模型进行垃圾信息检测</li>
        <li>使用ROC曲线、混淆矩阵、交叉验证等多种评估方法优化模型性能和阈值选择</li>
      </ul>
      <p><strong>使用的技术：</strong> Python, TensorFlow/Keras, LSTM, TF-IDF, NLTK, scikit-learn, Pandas, Matplotlib, Seaborn, WordCloud</p>
      <p><strong>时间：</strong> 2024年8月</p>
    </div>
  </div>

  <div class="project-entry">
    <h3><i class="fas fa-home" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>Airbnb价格分析与预测系统</h3>
    <div class="project-details">
      <p>基于各种物业特征和位置数据预测纽约市Airbnb房源价格，实现传统机器学习和深度学习两种价格预测方法。<a href="https://github.com/M0M0KO/airbnb-price-prediction" target="_blank"><i class="fab fa-github"></i> GitHub</a></p>
      <ul>
        <li>对包含49,000个房源的纽约市Airbnb数据集进行探索性分析，创建热力图和地理空间可视化查看价格分布模式</li>
        <li>使用GeoPandas和Contextily进行地理空间分析，结合NYC社区边界数据可视化房源分布和价格热点区域</li>
        <li>实现两种预测方法：RandomForest回归模型和Keras深度神经网络（双隐层架构）进行价格预测</li>
        <li>通过特征工程和数据预处理提升模型性能，使用RMSE和MAE评估模型准确性</li>
      </ul>
      <p><strong>使用的技术：</strong> Python, Pandas, Scikit-learn, Keras/TensorFlow, GeoPandas, Contextily, Matplotlib, Seaborn, RandomForest</p>
      <p><strong>时间：</strong> 2024年1月</p>
    </div>
  </div>
  
  <div class="project-entry">
    <h3><i class="fas fa-comment" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>航空公司情感分析系统</h3>
    <div class="project-details">
      <p>为航空相关推文开发情感分析系统，将客户反馈分类为积极、消极或中性，实现传统机器学习和深度学习两种方法对比。<a href="https://github.com/M0M0KO/airline-sentiment" target="_blank"><i class="fab fa-github"></i> GitHub</a></p>
      <ul>
        <li>为Twitter数据设计文本预处理流程（去除标签、提及、表情符号、URL，词元化处理）</li>
        <li>实现两种不同的方法：基于CountVectorizer的朴素贝叶斯分类器和基于LSTM的深度学习模型</li>
        <li>构建双层LSTM网络架构，包含300维词嵌入层、128和64神经元的LSTM层、Dropout正则化和早停机制</li>
        <li>使用词云、ROC曲线、混淆矩阵等可视化技术分析情感分布和模型性能</li>
      </ul>
      <p><strong>使用的技术：</strong> Python, TensorFlow/Keras, LSTM, 词嵌入, scikit-learn, NLTK, Pandas, Matplotlib, Seaborn, Plotly, WordCloud</p>
      <p><strong>时间：</strong> 2023年12月</p>
    </div>
  </div>

  <div class="project-entry">
    <h3><i class="fas fa-smoking" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>吸烟行为检测系统</h3>
    <div class="project-details">
      <p>本科毕业论文项目，在导师指导下学习结合YOLO目标检测与MediaPipe骨架跟踪技术，识别视频流中的吸烟动作。<a href="https://github.com/M0M0KO/smoking-detection" target="_blank"><i class="fab fa-github"></i> GitHub</a></p>
      <ul>
        <li>使用YOLO目标检测技术在视频中识别香烟和相关物体</li>
        <li>使用MediaPipe进行实时骨架跟踪和姿态估计</li>
        <li>在指导下设计算法识别特征吸烟手到嘴动作模式</li>
      </ul>
      <p><strong>使用的技术：</strong> YOLO, MediaPipe, 姿态估计, 动作识别, PyTorch, OpenCV</p>
      <p><strong>时间：</strong> 2023年4月</p>
      <p><strong>成果：</strong> 专利申请(202310277784.1)，3项软件著作权，论文获得优秀毕业论文</p>
    </div>
  </div>

  <div class="project-entry">
    <h3><i class="fas fa-heartbeat" style="font-size: 1.2em; color: #4285F4; margin-right: 0.5em;"></i>心脏病预测系统</h3>
    <div class="project-details">
      <p>基于患者数据和健康指标预测心脏病的可能性<a href="https://github.com/M0M0KO/heart-disease-prediction" target="_blank"><i class="fab fa-github"></i> GitHub</a></p>
      <ul>
        <li>对包含各种健康指标和人口统计信息的数据集进行探索性分析</li>
        <li>通过特征选择和工程方法，识别心脏病的关键预测因素</li>
        <li>实现和比较多种分类算法，包括K-近邻、支持向量机、随机森林和朴素贝叶斯</li>
        <li>使用交叉验证技术优化模型参数提高预测性能</li>
        <li>创建可视化来理解健康因素之间的关系</li>
      </ul>
      <p><strong>使用的技术：</strong> Python, TensorFlow 2.11.0, scikit-learn, Pandas, NumPy, Matplotlib, Seaborn</p>
      <p><strong>时间：</strong> 2022年5月</p>
    </div>
  </div>
</div>

---

## 研究兴趣

<div class="research-interests">
  <div class="interest-area">
    <h3><i class="fas fa-brain" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>医学人工智能</h3>
    <ul>
      <li>学习用于医学图像分析和疾病诊断的深度学习</li>
      <li>多模态临床数据整合和特征提取</li>
      <li>探索临床应用的计算机辅助诊断系统</li>
    </ul>
  </div>
  
  <div class="interest-area">
    <h3><i class="fas fa-robot" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>具身智能</h3>
    <ul>
      <li>研究机器人如何通过与世界的物理交互产生智能</li>
      <li>探索具身智能体中感知与行动的联系</li>
      <li>学习机器人应用中的强化学习</li>
    </ul>
  </div>
  
  <div class="interest-area">
    <h3><i class="fas fa-eye" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>计算机视觉</h3>
    <ul>
      <li>基于注意力的目标检测架构</li>
      <li>人体姿态估计和行为识别</li>
      <li>实际应用的视觉特征提取</li>
    </ul>
  </div>
  
  <div class="interest-area">
    <h3><i class="fas fa-users" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>多智能体系统</h3>
    <ul>
      <li>理解多个智能体如何协同工作</li>
      <li>对智能体群体中的涌现行为和集体智能好奇</li>
      <li>想要学习多智能体人工智能系统的基础知识</li>
    </ul>
  </div>
</div>

---

## 技术技能

<div class="skills-section">
  <div class="skills-grid">
    <div class="skill-category">
      <h3><i class="fas fa-code" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>编程语言</h3>
      <ul>
        <li>Python</li>
        <li>C, Java, SQL</li>
        <li>C#, JavaScript, Vue</li>
      </ul>
    </div>
    
    <div class="skill-category">
      <h3><i class="fas fa-brain" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>人工智能与机器学习</h3>
      <ul>
        <li><strong>框架：</strong> PyTorch, TensorFlow</li>
        <li><strong>领域：</strong> 计算机视觉, 深度学习, 强化学习</li>
        <li><strong>技术：</strong> CNN, 注意力机制, 迁移学习</li>
      </ul>
    </div>
    
    <div class="skill-category">
      <h3><i class="fas fa-tools" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>开发工具</h3>
      <ul>
        <li><strong>版本控制：</strong> Git, GitHub</li>
        <li><strong>文档：</strong> LaTeX, Markdown</li>
        <li><strong>环境：</strong> Linux, Jupyter, Docker</li>
      </ul>
    </div>
    
    <div class="skill-category">
      <h3><i class="fas fa-chart-bar" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>数据分析</h3>
      <ul>
        <li><strong>库：</strong> NumPy, Pandas, SciPy</li>
        <li><strong>可视化：</strong> Matplotlib, Seaborn, Plotly</li>
      </ul>
    </div>
    
    <div class="skill-category">
      <h3><i class="fas fa-language" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>语言</h3>
      <ul>
        <li><strong>中文：</strong> 母语</li>
        <li><strong>英语：</strong> </li>
        <li>  - 雅思: 总分 6.0 (听力: 6.5, 阅读: 6.5, 写作: 5.5, 口语: 6.0)</li>
        <li> - CET-6: 总分 467</li>
      </ul>
    </div>
    
    <div class="skill-category">
      <h3><i class="fas fa-certificate" style="font-size: 1.2em; margin-right: 0.5em; color: #4285F4;"></i>证书</h3>
      <ul>
        <li>DevCloud夏令营培训（华为）</li>
        <li>人工智能基础Python（山东大学）</li>
        <li>深度学习基础（山东大学）</li>
      </ul>
    </div>
  </div>
</div>

---

## 专业发展与学习方向

<div class="professional-development">
  <div class="current-learning">
    <h3><i class="fas fa-brain" style="font-size: 1.2em; margin-right: 0.5em; color: var(--global-text-color);"></i>当前学习重点</h3>
    <p>具身智能和机器人学方向的自主学习，关注以下领域：</p>
    <ul>
      <li><strong>具身人工智能核心算法：</strong> 学习强化学习、模仿学习、模型预测控制和适用于机器人的扩散模型等基础知识</li>
      <li><strong>视觉-语言-动作模型：</strong> 了解将感知、语言理解和动作生成集成用于机器人控制的基础模型</li>
      <li><strong>机器人学习：</strong> 探索各种环境中的操作和导航技术，关注仿真到现实的迁移学习</li>
      <li><strong>多智能体系统：</strong> 初步接触多智能体强化学习场景中的协调机制和涌现行为</li>
      <li><strong>仿真环境：</strong> 开始学习MuJoCo、Isaac Gym或Habitat等具身人工智能研究和开发环境</li>
    </ul>
  </div>
  
  <div class="key-resources">
    <h3><i class="fas fa-book" style="font-size: 1.2em; margin-right: 0.5em; color: var(--global-text-color);"></i>关键学习资源</h3>
    <ul>
      <li>
        <strong>GitHub资源：</strong>
        <ul>
          <li><strong>Embodied-AI-Guide</strong> (<a href="https://github.com/tianxingchen/Embodied-AI-Guide" target="_blank">github.com/tianxingchen/Embodied-AI-Guide</a>)：具身智能研究综合指南（4.6k+星），这个仓库涵盖：
            <ul>
              <li>核心算法，包括强化学习、模仿学习、模型预测控制和扩散模型</li>
              <li>用于机器人控制的视觉-语言-动作(VLA)模型</li>
              <li>硬件平台和模拟器环境，如MuJoCo、Isaac Gym和Habitat</li>
              <li>适用于具身智能体的计算机视觉和3D感知技术</li>
              <li>用于操作和导航任务的机器人学习方法</li>
            </ul>
          </li>
          <li><strong>Embodied-AI-Paper-List</strong> (<a href="https://github.com/Lumina-EAI/Embodied-AI-Paper-List" target="_blank">github.com/Lumina-EAI/Embodied-AI-Paper-List</a>)：按主题分类的重要研究论文精选集</li>
          <li><strong>Awesome-Embodied-AI-Job</strong> (<a href="https://github.com/StarCycle/Awesome-Embodied-AI-Job" target="_blank">github.com/StarCycle/Awesome-Embodied-AI-Job</a>)：跟踪具身智能研究机会的资源</li>
        </ul>
      </li>
      <li>
        <strong>研究文献：</strong>
        <ul>
          <li>关注来自ICRA、CoRL、NeurIPS、CVPR和ICLR会议聚焦于具身人工智能的最新论文</li>
          <li>学习机器人学习的基础模型，特别是视觉-语言-动作模型的研究</li>
          <li>跟踪基于大语言模型的机器人规划和控制发展</li>
          <li>探索机器人操作的仿真到现实迁移技术</li>
        </ul>
      </li>
    </ul>
  </div>
  
  <div class="future-directions">
    <h3><i class="fas fa-compass" style="font-size: 1.2em; margin-right: 0.5em; color: var(--global-text-color);"></i>我感兴趣的研究问题</h3>
    <ul>
      <li>机器人如何通过与环境互动发展智能？</li>
      <li>什么机制能让多个智能体自组织并发展专门角色？</li>
      <li>人工智能系统如何自动分解复杂任务并协作使用专门工具？</li>
      <li>物理具身在发展稳健和可泛化智能中扮演什么角色？</li>
    </ul>
  </div>
</div>

---

## 参考信息

<div class="references">
  <p>可根据需要提供专业和学术参考信息。</p>
</div>

<style>
  /* Global Styles */
  h2 {
    margin-top: 2em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    border-bottom: 2px solid var(--global-border-color);
    color: var(--global-text-color);
    font-weight: 600;
  }
  
  hr {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.15), rgba(0, 0, 0, 0));
    margin: 2em 0;
  }
  
  .download-button {
    text-align: center;
    margin: 1.5em 0;
  }
  
  .btn-primary {
    display: inline-block;
    padding: 0.5em 1em;
    background-color: #2a76dd;
    color: white;
    text-decoration: none;
    border-radius: 4px;
    font-weight: bold;
    transition: background-color 0.3s ease;
  }
  
  .btn-primary:hover {
    background-color: #1a66cd;
    text-decoration: none;
  }

  /* Section Styles */
  .education-entry,
  .experience-entry,
  .project-entry,
  .paper {
    margin-bottom: 2em;
    padding: 1.5em;
    background-color: var(--global-bg-color);
    border: 1px solid var(--global-border-color);
    border-radius: 8px;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    transition: all 0.2s ease-in-out;
  }
  
  .education-entry:hover,
  .experience-entry:hover,
  .project-entry:hover,
  .paper:hover {
    transform: translateY(-3px);
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
  }
  
  .education-entry h3,
  .experience-entry h3,
  .project-entry h3,
  .paper h3,
  .interest-area h3 {
    margin-bottom: 0.8em;
    color: var(--global-text-color);
    font-weight: 600;
    border-bottom: 1px solid var(--global-border-color);
    padding-bottom: 0.5em;
  }
  
  .education-entry p,
  .experience-entry p,
  .project-entry p,
  .paper p {
    margin: 0.5em 0;
    line-height: 1.5;
    color: var(--global-text-color);
  }
  
  .education-entry ul,
  .experience-entry ul,
  .project-details ul,
  .interest-area ul,
  .current-learning ul,
  .key-resources ul,
  .software-copyrights ul {
    padding-left: 1.5em;
    color: var(--global-text-color);
  }
  
  .education-entry li,
  .experience-entry li,
  .project-details li,
  .interest-area li,
  .current-learning li,
  .key-resources li,
  .software-copyrights li {
    margin-bottom: 0.5em;
    line-height: 1.4;
  }
  
  .project-details {
    margin-top: 1em;
  }
  
  /* Publication Styles */
  .contribution {
    font-style: italic;
    color: var(--global-text-color-light);
    border-left: 3px solid var(--global-border-color);
    padding-left: 10px;
    margin-top: 0.8em;
    background-color: var(--global-bg-color);
    padding: 0.5em 1em;
    border-radius: 0 4px 4px 0;
  }
  
  /* Research Interests */
  .research-interests {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(400px, 1fr));
    grid-gap: 1.5em;
  }
  
  .interest-area {
    padding: 1.5em;
    background-color: var(--global-bg-color);
    border: 1px solid var(--global-border-color);
    border-radius: 8px;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    transition: all 0.2s ease-in-out;
  }
  
  .interest-area:hover {
    transform: translateY(-3px);
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
  }
  
  /* Skills Grid */
  .skills-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
    grid-gap: 1.5em;
  }
  
  .skill-category {
    background-color: var(--global-bg-color);
    border: 1px solid var(--global-border-color);
    padding: 1.5em;
    border-radius: 8px;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    transition: all 0.2s ease-in-out;
  }
  
  .skill-category:hover {
    transform: translateY(-3px);
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
  }
  
  .skill-category h3 {
    margin-top: 0;
    margin-bottom: 0.8em;
    color: var(--global-text-color);
    font-weight: 600;
    border-bottom: 1px solid var(--global-border-color);
    padding-bottom: 0.5em;
  }
  
  /* Achievements */
  .achievements {
    display: grid;
    grid-template-columns: 1fr;
    grid-gap: 1.5em;
  }
  
  .achievement-item {
    background-color: var(--global-bg-color);
    border: 1px solid var(--global-border-color);
    border-radius: 8px;
    overflow: hidden;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    padding: 1.5em;
    transition: all 0.2s ease-in-out;
  }
  
  .achievement-item:hover {
    transform: translateY(-3px);
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
  }
  
  .achievement-content h4 {
    margin: 0 0 0.5em 0;
    color: var(--global-text-color);
    display: flex;
    align-items: center;
    font-weight: 600;
  }
  
  .achievement-content p {
    margin: 0.5em 0;
    font-size: 0.95em;
    line-height: 1.5;
    color: var(--global-text-color);
  }
  
  .achievement-desc {
    font-size: 0.9em !important;
    color: var(--global-text-color-light) !important;
    margin-top: 0.5em !important;
  }
  
  /* Patents and Software */
  .patents {
    margin-bottom: 2em;
  }
  
  .patent-item {
    padding: 1.5em;
    border-radius: 8px;
    background-color: var(--global-bg-color);
    border: 1px solid var(--global-border-color);
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    transition: all 0.2s ease-in-out;
    margin-bottom: 1.5em;
  }
  
  .patent-item:hover {
    transform: translateY(-3px);
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
  }
  
  .patent-item h3 {
    margin-top: 0;
    margin-bottom: 0.8em;
    color: var(--global-text-color);
    font-weight: 600;
    border-bottom: 1px solid var(--global-border-color);
    padding-bottom: 0.5em;
  }
  
  .patent-item p {
    margin: 0.3em 0;
    line-height: 1.4;
    color: var(--global-text-color);
  }
  
  .software-copyrights {
    padding: 1.5em;
    border-radius: 8px;
    background-color: var(--global-bg-color);
    border: 1px solid var(--global-border-color);
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
  }
  
  .software-copyrights h3 {
    margin-top: 0;
    margin-bottom: 0.8em;
    color: var(--global-text-color);
    font-weight: 600;
    border-bottom: 1px solid var(--global-border-color);
    padding-bottom: 0.5em;
  }
  
  .software-copyrights li {
    margin-bottom: 1em;
    color: var(--global-text-color);
  }
  
  /* Professional Development */
  .professional-development > div {
    padding: 1.5em;
    background-color: var(--global-bg-color);
    border: 1px solid var(--global-border-color);
    border-radius: 8px;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    margin-bottom: 1.5em;
    transition: all 0.2s ease-in-out;
  }
  
  .professional-development > div:hover {
    transform: translateY(-3px);
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
  }
  
  .professional-development h3 {
    margin-top: 0;
    margin-bottom: 0.8em;
    color: var(--global-text-color);
    font-weight: 600;
    border-bottom: 1px solid var(--global-border-color);
    padding-bottom: 0.5em;
  }
  
  /* References */
  .references {
    padding: 1.5em;
    background-color: var(--global-bg-color);
    border: 1px solid var(--global-border-color);
    border-radius: 8px;
    text-align: center;
    font-style: italic;
    color: var(--global-text-color);
  }
  
  /* Icons */
  .fa, .fas, .far, .fab {
    color: var(--global-text-color);
  }
  
  .achievement-content .fas {
    color: inherit;
  }
  
  /* Responsive Adjustments */
  @media (max-width: 768px) {
    .research-interests,
    .skills-grid {
      grid-template-columns: 1fr;
    }
  }
</style>